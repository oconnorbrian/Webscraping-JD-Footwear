{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43aca8e0-1789-4891-bab2-43bff300e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setting header to mimic a request from a web browser and delays between requests\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "delay = 2  # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e13f51b-6b2f-4198-8ce0-965dd0b2bb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success!\n"
     ]
    }
   ],
   "source": [
    "# Firstly, test to see if URL is correct\n",
    "url = ('https://www.jdsports.ie/men/mens-footwear/')\n",
    "page = requests.get(url)\n",
    "# Error Handling\n",
    "if page.status_code == 200:\n",
    "    print('Success!')\n",
    "else:\n",
    "    print('An error has occurred. Please ensure url is correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1123111e-bdee-4835-9573-225d795cfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(url):\n",
    "    # Retrieving data from the url\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    \n",
    "  # Extracting hotel information\n",
    "    shoes_info = soup.find_all('span', {'class': 'itemContainer'})\n",
    "\n",
    "    # Creating lists to store hotel data\n",
    "    shoes_names = []\n",
    "    shoes_prices = []\n",
    "\n",
    "    # Looping through hotel information to extract data\n",
    "    for info in shoes_info:\n",
    "        # Extracting hotel name\n",
    "        shoes_name = info.find('span', {'class': 'itemTitle'}).text.strip()\n",
    "        shoes_names.append(shoes_name)\n",
    "\n",
    "        # Extracting hotel price\n",
    "        shoes_price = info.find('div', {'class': 'itemPrice'}).text.strip()\n",
    "        shoes_prices.append(shoes_price)\n",
    "\n",
    "       \n",
    "    # Creating a dictionary with the extracted data\n",
    "    shoes_data = {\n",
    "        'Shoe Name': shoes_names,\n",
    "        'Price': shoes_prices,\n",
    "    }\n",
    "\n",
    "    return shoes_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a3bf95b-d4a5-46a3-8df4-f6f6021d7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function get_next_page takes a BeautifulSoup object representing a webpage as input and returns the URL of the next page of hotel listings, if it is available\n",
    "def get_next_page(soup):\n",
    "    # Finding the next page url from the pagination element\n",
    "    pagination = soup.find('div', {'class': 'pageLinks'})\n",
    "    if pagination:\n",
    "        next_page = pagination.find('a', {'rel': 'next'})\n",
    "        if next_page:\n",
    "            return 'https://www.jdsports.ie' + next_page['href']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "767f3674-dd4d-4609-899e-3cda60d12e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully scraped and saved to hotel_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Starting url\n",
    "url = 'https://www.jdsports.ie/men/mens-footwear/'\n",
    "    \n",
    "all_shoes_data = []  # List to store all hotel data\n",
    "\n",
    "# Looping through all pages and scraping hotel data\n",
    "while url:\n",
    "    shoes_data = scrape_data(url)\n",
    "    all_shoes_data.append(shoes_data)\n",
    "    time.sleep(delay)\n",
    "    url = get_next_page(BeautifulSoup(requests.get(url, headers=headers).content, 'lxml'))\n",
    "\n",
    "# Combining all hotel data into a single dataframe\n",
    "df = pd.concat([pd.DataFrame(data) for data in all_shoes_data])\n",
    "\n",
    "# Saving dataframe to a CSV file\n",
    "df.to_csv('shoes_data.csv', index=False)\n",
    "\n",
    "print('Data successfully scraped and saved to hotel_data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
